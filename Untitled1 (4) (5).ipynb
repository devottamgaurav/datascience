{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827e3eea-a123-4e98-ae47-895bbd2a7501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.21.6\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.5\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.21.6)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1304 sha256=f58524aaabad7950448e9f186b44b096c9adf34c0b30b10fe2135927c09f92d8\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.0.2 scipy-1.7.3 sklearn-0.0 threadpoolctl-3.1.0\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (1.21.6)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (21.3)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /srv/conda/envs/notebook/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.4 matplotlib-3.5.3 pillow-9.2.0\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.1-py3-none-any.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (1.21.6)\n",
      "Requirement already satisfied: typing_extensions in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (4.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas>=0.25->seaborn) (2022.4)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.1\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: graphviz\n",
      "Successfully installed graphviz-0.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "!pip install tabulate\n",
    "!pip install seaborn\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca237b95-0d20-4a8a-b55e-7f84fb18231d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "from datetime import date\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "from datetime import timedelta, date\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_graphviz \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a08df706-65ab-4f82-8bfe-14d2074f6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Assining_Variables():\n",
    "    fle1 = \"6M-0K-99K.users.dataset.public.csv\"\n",
    "    fle2 = \"Buyers-repartition-by-country.csv\"\n",
    "    fle3 = \"Comparison-of-Sellers-by-Gender-and-Country.csv\"\n",
    "    fle4 = \"Countries-with-Top-Sellers-(Fashion-C2C).csv\"\n",
    "    return fle1,fle2,fle3,fle4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58914523-583f-40fa-af58-2ae139ac4216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(fle1,fle2,fle3,fle4):\n",
    "    df_air_visit_data = pd.read_csv(fle1)\n",
    "    df_air_reserve = pd.read_csv(fle2)\n",
    "    df_air_store_info = pd.read_csv(fle3)\n",
    "    df_date_info = pd.read_csv(fle4)  \n",
    "    return df_air_visit_data,df_air_reserve,df_air_store_info,df_date_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e127c853-7fed-43c0-94c3-091c434e3e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def Counting_NAN_Values(dfff):\n",
    "        df_nan = pd.DataFrame(columns=['Nan count'])\n",
    "        nan_col = list(dfff.columns.tolist())\n",
    "        total_nan = 0\n",
    "        for col in nan_col:\n",
    "            nan_cnt = dfff[col].isnull().sum()\n",
    "            df_nan.loc[col] = nan_cnt\n",
    "            total_nan += nan_cnt\n",
    "        print(tabulate(df_nan, headers = 'keys', tablefmt = 'psql'))\n",
    "        return df_nan['Nan count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58cd7f99-3c28-463a-9969-b63781619fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset_Cleaning(dff):\n",
    "        dfff = dff.isna().sum().sum()\n",
    "        print(\"Total NAN values are : {0}\".format(dfff))\n",
    "        dff_nan = dff[pd.isnull(dff).any(axis=1)]\n",
    "        print(\"Data with at least 1 NAN values: {0}\".format(len(dff_nan.index)))\n",
    "        df_nan_all = dff[pd.isnull(dff).all(1)]\n",
    "        print(\"Rows filled NAN data: {0}\".format(len(df_nan_all.index)))\n",
    "        df_air_store = dff.identifierHash.isnull().sum()\n",
    "        #df_hpg_store = dff.hpg_store_id.isnull().sum()\n",
    "        print(\"Count of NAN values on identifierHash are: {0}\".format(df_air_store))\n",
    "        #print(\"Count of NAN values on hpg_store_id are: {0}\".format(df_hpg_store))\n",
    "        nan_ids_df = dff[dff.identifierHash.isnull()]\n",
    "        len_invalid_id = len(nan_ids_df.index)\n",
    "        print(\"Number of Invalid IDs (identifierhash) are : {0}\".format(len_invalid_id))\n",
    "        df_nadn = Counting_NAN_Values(dff)\n",
    "        return dfff,df_nadn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0830ff89-320c-47b5-a029-571cefa6e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nan_Percent_Computation(dffff):\n",
    "        nan_values_cnt,df_nafn = Dataset_Cleaning(dffff)\n",
    "        total_values_cnt = dffff.shape[0]*dffff.shape[1]\n",
    "        print(\"Total Values' Counts are : {0}\".format(total_values_cnt))\n",
    "        total_correct_values_cnt = (total_values_cnt - nan_values_cnt)\n",
    "        print(\"Total Correct Values' Counts are : {0}\".format(total_correct_values_cnt))\n",
    "        return total_correct_values_cnt,nan_values_cnt,df_nafn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "feb9df01-be12-4f3d-b234-222edaebec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pie_Chart_NAN_Column_Plotting(dft_val1,dfg,total_crt_value_cnt,nan_value_cnt):\n",
    "    dft = pd.DataFrame({'Data': ['Correct Values', 'NAN Values'],\n",
    "                          'ValueCount': [total_crt_value_cnt,nan_value_cnt]})\n",
    "        # Plotting the pie chart for above dataframe\n",
    "    #dft.groupby(['Data']).sum().plot(kind='pie', y='Value Count', autopct='%1.0f%%')\n",
    "    # Data to plot\n",
    "    lab1 = dft.Data.values\n",
    "    sdd = dft.ValueCount.values\n",
    "    #sizes = [215, 130,215, 130,215, 130]\n",
    "    color = ['lightcoral', 'lightskyblue']\n",
    "    explode1 = (0.1, 0)  # explode 1st slice\n",
    "    # Plot\n",
    "    plt.pie(sdd, explode=explode1, labels=lab1, colors=color,autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "   \n",
    "    # Define the ratio of gap of each fragment in a tuple\n",
    "    #explode = (0.05, 0.05, 0.05,0.05, 0.05, 0.05,0.05, 0.05, 0.05,0.05, 0.05, 0.05,0.05, 0.05)\n",
    "    # DataFrame of each student and the votes they get df_nan_disp['Data Name'],df_nan_disp['NAN Count for each Column']\n",
    "    #dft = pd.DataFrame({'Data Name': dfg.columns,'NAN Count for each Column':dft_val1})\n",
    "    # Plotting the pie chart for above dataframe\n",
    "    # Data to plot\n",
    "    #labels = dfg.columns.values\n",
    "    #sddd = dft_val1.values\n",
    "    #sizes = [215, 130,215, 130,215, 130,215, 130,215, 130,215, 130,215, 130]\n",
    "    #colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "    #explode = (0.1, 0,0.1, 0,0.1, 0,0.1, 0,0.1, 0,0.1, 0,0.1, 0)  # explode 1st slice\n",
    "    # Plot\n",
    "    #plt.pie(sddd, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "    #plt.axis('equal')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd55cc85-6487-4780-9264-e2386ac83200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Final_Dataset():\n",
    "        fle1,fle2,fle3,fle4 = Assining_Variables()\n",
    "        df_air_visit_data,df_air_reserve,df_air_store_info,df_date_info = load_dataset(fle1,fle2,fle3,fle4)\n",
    "        #df_air_visit_data,df_air_reserve,df_air_store_info,df_date_info,df_store_id_relation,df_hpg_reserve,df_hpg_store_info = self.load_dataset()\n",
    "        h1,t1 = os.path.split(fle1)\n",
    "        h2,t2 = os.path.split(fle2)\n",
    "        h3,t3 = os.path.split(fle3)\n",
    "        h4,t4 = os.path.split(fle4)\n",
    "        print(\"The shape of {0} is {1}\".format(t1,df_air_visit_data.shape),end=\"\\n\")\n",
    "        print(\"The shape of {0} is {1}\".format(t2,df_air_reserve.shape),end=\"\\n\")\n",
    "        print(\"The shape of {0} is {1}\".format(t3,df_air_store_info.shape),end=\"\\n\")\n",
    "        print(\"The shape of {0} is {1}\".format(t4,df_date_info.shape),end=\"\\n\")\n",
    "        #df_n = pd.concat([df_air_visit_data['country'],df_date_info], axis=1, join=\"outer\")\n",
    "        df_n = pd.merge(df_air_visit_data,df_date_info,on='country',how=\"outer\")\n",
    "        df_nn = pd.merge(df_air_reserve,df_air_store_info,on='country',how=\"right\")\n",
    "        df = pd.concat([df_n,df_nn], axis=1, join=\"outer\")\n",
    "        #df = pd.merge(df_n,df_nn,on='country',how=\"right\")\n",
    "        #print(df_n)\n",
    "        print(df)\n",
    "        print(df_n.shape)\n",
    "        print(df_nn.shape)\n",
    "        print(df.shape)\n",
    "        #df_nadjn = Counting_NAN_Values(df)\n",
    "        \n",
    "        total_crt_value_cnt,nan_value_cnt,df_najn = Nan_Percent_Computation(df)\n",
    "        #Pie_Chart_Plotting(total_crt_value_cnt,nan_value_cnt)\n",
    "        df_nan_disp = pd.DataFrame()\n",
    "        Pie_Chart_NAN_Column_Plotting(df_najn,df,total_crt_value_cnt,nan_value_cnt)\n",
    "        \n",
    "        #Printing the number of NANs in each column\n",
    "        n_rows = len(df)\n",
    "        for i in range(0,len(df_najn)):\n",
    "            nan_percent_in_each_col = ((df_najn/n_rows)*100)\n",
    "            df_nan_disp = pd.DataFrame({'% of NAN Count':nan_percent_in_each_col})\n",
    "        print(tabulate(df_nan_disp, headers = 'keys', tablefmt = 'psql'))\n",
    "        #print(df)\n",
    "        #print(df)\n",
    "        \n",
    "        #df = df.dropna(subset=['visitors'],inplace=True)\n",
    "        #print(df)\n",
    "       # from sklearn.impute import SimpleImputer\n",
    "        #df = SimpleImputer(strategy='constant',fill_value='air_8093d0b565e9dbdf')\n",
    "        \"\"\"from sklearn.preprocessing import OneHotEncoder\n",
    "        from sklearn.compose import ColumnTransformer\"\"\"\n",
    "        \"\"\"cat_feat = ['air_store_id']\n",
    "        one_hot = OneHotEncoder()\n",
    "        transformer = ColumnTransformer([(\"one_hot\",one_hot,cat_feat)],remainder=\"passthrough\")\n",
    "        transformed_X = transformer.fit_transform(df)\n",
    "        print(transformed_X)\"\"\"\n",
    "        \"\"\"total_crt_value_cnt1,nan_value_cnt1,df_najn1 = Nan_Percent_Computation(df)\n",
    "        #Pie_Chart_Plotting(total_crt_value_cnt,nan_value_cnt)\n",
    "        df_nan_disp1 = pd.DataFrame()\n",
    "        #Pie_Chart_NAN_Column_Plotting(df_najn1,df,total_crt_value_cnt,nan_value_cnt)\n",
    "        \n",
    "        #Printing the number of NANs in each column\n",
    "        n_rows1 = len(df)\n",
    "        for i in range(0,len(df_najn1)):\n",
    "            nan_percent_in_each_col1 = ((df_najn1/n_rows1)*100)\n",
    "            df_nan_disp1 = pd.DataFrame({'% of NAN Count':nan_percent_in_each_col1})\n",
    "        print(tabulate(df_nan_disp1, headers = 'keys', tablefmt = 'psql'))\"\"\"\n",
    "        #print(df)\n",
    "        \"\"\"print(df.air_store_id.value_counts())\n",
    "        print(df.visit_date.value_counts())\n",
    "        print(df.visitors.value_counts())\n",
    "        print(df.visit_datetime.value_counts())\n",
    "        print(df.reserve_datetime.value_counts())\n",
    "        #print(df.reserve_visitors.value_counts())\n",
    "        print(df.genre_name.value_counts())\n",
    "        print(df.area_name.value_counts())\n",
    "        #print(df.latitude.value_counts())\n",
    "        #print(df.longitude.value_counts())\n",
    "        print(df.hpg_store_id.value_counts())\n",
    "        print(df.reserve_visitors.median())\"\"\"\n",
    "        \n",
    "        \"\"\"print(df.latitude.median())\n",
    "        print(df.longitude.median())\"\"\"\n",
    "        \n",
    "        \"\"\"df.drop(['calendar_date','day_of_week','holiday_flg'],axis=1,inplace=True)\n",
    "        #df.drop(df['calendar_date'],axis=1,inplace=True)\n",
    "        df[['visit_date','visitors','visit_datetime','reserve_datetime','reserve_visitors','hpg_store_id']] = df[['visit_date','visitors','visit_datetime','reserve_datetime','reserve_visitors','hpg_store_id']].replace(np.nan,9999)\n",
    "        #df[['latitude','longitude','visit_datetime','reserve_datetime','reserve_visitors','hpg_store_id','hpg_area_name','hpg_genre_name']] = df[['latitude','longitude','visit_datetime','reserve_datetime','reserve_visitors','hpg_store_id','hpg_area_name','hpg_genre_name']].replace(np.nan,9999)\n",
    "        df[['area_name','latitude','longitude','genre_name']] = df[['area_name','latitude','longitude','genre_name']].replace(np.nan,9999)\n",
    "        df.drop(df.index[df['latitude'] == 9999], inplace=True)\n",
    "        df.drop(df.index[df['longitude'] == 9999], inplace=True)\n",
    "        #df.drop(df.index[df['visit_datetime'] == 9999], inplace=True)\n",
    "        #df.drop(df.index[df['reserve_datetime'] == 9999], inplace=True)\n",
    "        #df.drop(df.index[df['reserve_visitors'] == 9999], inplace=True)\n",
    "        #df.drop(df.index[df['hpg_store_id'] == 9999], inplace=True)\"\"\"\n",
    "        #df['air_store_id'] = df['air_store_id'].replace(np.nan,9999)\n",
    "        #df.drop(df.index[df['air_store_id'] == 9999], inplace=True)\n",
    "        \"\"\"df.drop(df.index[df['area_name'] == 9999], inplace=True)\n",
    "        df.drop(df.index[df['genre_name'] == 9999], inplace=True)\n",
    "        #df[['visitors']] = df[['visitors']].astype(int)\n",
    "        #df.reset_index()\n",
    "        df['air_store_id'] = df['air_store_id'].replace(np.nan,\"air_8093d0b565e9dbdf\")\n",
    "        df.drop(df.index[df['air_store_id'] == \"air_8093d0b565e9dbdf\"], inplace=True)\n",
    "        df['visit_datetime'] = df['visit_datetime'].replace(np.nan,\"2016-12-22 19:00:00\")\n",
    "        #df.drop(df.index[df['visit_datetime'] == \"2016-12-22 19:00:00\"], inplace=True)\n",
    "        df['reserve_datetime'] = df['reserve_datetime'].replace(np.nan,\"2016-12-12 21:00:00\")\n",
    "        #df.drop(df.index[df['reserve_datetime'] == \"2016-12-12 21:00:00\"], inplace=True)\n",
    "        df['hpg_store_id'] = df['hpg_store_id'].replace(np.nan,\"hpg_011e799ba201ad2e\")\n",
    "        df['visit_date'] = df['visit_date'].replace(np.nan,\"17-03-2017\")\n",
    "        df['reserve_visitors'] = df['reserve_visitors'].replace(np.nan,3.0)\n",
    "        df['visitors'] = df['visitors'].replace(np.nan,8.0)\n",
    "        #df.drop(df.index[df['reserve_visitors'] == 2.0], inplace=True)\n",
    "        print(df)\n",
    "        df_nadbjn = Counting_NAN_Values(df)\"\"\"\n",
    "        #return df,fnl_flle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7247cee6-544b-4537-ac08-98fbc031df85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of 6M-0K-99K.users.dataset.public.csv is (98913, 24)\n",
      "The shape of Buyers-repartition-by-country.csv is (62, 32)\n",
      "The shape of Comparison-of-Sellers-by-Gender-and-Country.csv is (73, 19)\n",
      "The shape of Countries-with-Top-Sellers-(Fashion-C2C).csv is (19, 26)\n",
      "            identifierHash  type               country language  \\\n",
      "0     -7279641312655250028  user            Etats-Unis       en   \n",
      "1     -6727673442828273069  user            Etats-Unis       en   \n",
      "2      2543719509187236735  user            Etats-Unis       en   \n",
      "3      6412144644819322909  user            Etats-Unis       en   \n",
      "4      6359422170336773354  user            Etats-Unis       en   \n",
      "...                    ...   ...                   ...      ...   \n",
      "98908 -2153409213600872300  user                 Samoa       en   \n",
      "98909  5863332066763309084  user               Mayotte       fr   \n",
      "98910  6319027581994901279  user  Saint Kitts et Nevis       en   \n",
      "98911 -2380644551967973010  user             Swaziland       fr   \n",
      "98912  7383975515500598791  user            Île de Man       en   \n",
      "\n",
      "       socialNbFollowers  socialNbFollows  socialProductsLiked  \\\n",
      "0                      3                8                    0   \n",
      "1                      3                8                    0   \n",
      "2                      3                8                    0   \n",
      "3                      3                8                    0   \n",
      "4                      3                8                    0   \n",
      "...                  ...              ...                  ...   \n",
      "98908                  3                8                    0   \n",
      "98909                  3                8                    0   \n",
      "98910                  3                8                    0   \n",
      "98911                  3                8                    0   \n",
      "98912                  3                8                    0   \n",
      "\n",
      "       productsListed  productsSold  productsPassRate  ...  \\\n",
      "0                   0             0               0.0  ...   \n",
      "1                   0             0               0.0  ...   \n",
      "2                   0             0               0.0  ...   \n",
      "3                   0             0               0.0  ...   \n",
      "4                   0             0               0.0  ...   \n",
      "...               ...           ...               ...  ...   \n",
      "98908               0             0               0.0  ...   \n",
      "98909               0             0               0.0  ...   \n",
      "98910               0             0               0.0  ...   \n",
      "98911               0             0               0.0  ...   \n",
      "98912               0             0               0.0  ...   \n",
      "\n",
      "       meanproductswished_y  meanproductsliked_y totalbought  totalwished  \\\n",
      "0                     34.66                35.28       354.0       4021.0   \n",
      "1                      3.38                31.79        55.0        115.0   \n",
      "2                      0.00                 1.00         0.0          0.0   \n",
      "3                     17.72               209.28       110.0        319.0   \n",
      "4                     24.00                38.33        24.0         72.0   \n",
      "...                     ...                  ...         ...          ...   \n",
      "98908                   NaN                  NaN         NaN          NaN   \n",
      "98909                   NaN                  NaN         NaN          NaN   \n",
      "98910                   NaN                  NaN         NaN          NaN   \n",
      "98911                   NaN                  NaN         NaN          NaN   \n",
      "98912                   NaN                  NaN         NaN          NaN   \n",
      "\n",
      "      totalproductsliked_y  meanfollowers_y  meanfollows  percentofappusers  \\\n",
      "0                   4092.0              9.5          8.9               54.0   \n",
      "1                   1081.0              7.8          8.4               79.0   \n",
      "2                      1.0              4.0          8.0                NaN   \n",
      "3                   3767.0              7.5          9.3               55.0   \n",
      "4                    115.0             12.7          8.3               66.0   \n",
      "...                    ...              ...          ...                ...   \n",
      "98908                  NaN              NaN          NaN                NaN   \n",
      "98909                  NaN              NaN          NaN                NaN   \n",
      "98910                  NaN              NaN          NaN                NaN   \n",
      "98911                  NaN              NaN          NaN                NaN   \n",
      "98912                  NaN              NaN          NaN                NaN   \n",
      "\n",
      "       percentofiosusers  meanseniority  \n",
      "0                   49.0    3060.336207  \n",
      "1                   64.0    3089.058824  \n",
      "2                    NaN    3201.000000  \n",
      "3                   55.0    3103.666667  \n",
      "4                   66.0    3085.666667  \n",
      "...                  ...            ...  \n",
      "98908                NaN            NaN  \n",
      "98909                NaN            NaN  \n",
      "98910                NaN            NaN  \n",
      "98911                NaN            NaN  \n",
      "98912                NaN            NaN  \n",
      "\n",
      "[98913 rows x 99 columns]\n",
      "(98913, 49)\n",
      "(73, 50)\n",
      "(98913, 99)\n",
      "Total NAN values are : 5337063\n",
      "Data with at least 1 NAN values: 98865\n",
      "Rows filled NAN data: 0\n",
      "Count of NAN values on identifierHash are: 0\n",
      "Number of Invalid IDs (identifierhash) are : 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80/3031088732.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFinal_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_80/3147553485.py\u001b[0m in \u001b[0;36mFinal_Dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#df_nadjn = Counting_NAN_Values(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtotal_crt_value_cnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnan_value_cnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_najn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNan_Percent_Computation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m#Pie_Chart_Plotting(total_crt_value_cnt,nan_value_cnt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdf_nan_disp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_80/2979623800.py\u001b[0m in \u001b[0;36mNan_Percent_Computation\u001b[0;34m(dffff)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mNan_Percent_Computation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdffff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mnan_values_cnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_nafn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset_Cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdffff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtotal_values_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdffff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdffff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Values' Counts are : {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_values_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtotal_correct_values_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_values_cnt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnan_values_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_80/3079985728.py\u001b[0m in \u001b[0;36mDataset_Cleaning\u001b[0;34m(dff)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlen_invalid_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnan_ids_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of Invalid IDs (identifierhash) are : {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_invalid_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdf_nadn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounting_NAN_Values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdfff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_nadn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_80/3320401755.py\u001b[0m in \u001b[0;36mCounting_NAN_Values\u001b[0;34m(dfff)\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnan_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m            \u001b[0mnan_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m            \u001b[0mdf_nan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnan_cnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m            \u001b[0mtotal_nan\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnan_cnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'keys'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtablefmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'psql'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2014\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m                 \u001b[0;31m# append a Series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   4578\u001b[0m     )\n\u001b[1;32m   4579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4580\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4582\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4817\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4818\u001b[0m         return self._reindex_axes(\n\u001b[0;32m-> 4819\u001b[0;31m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4820\u001b[0m         ).__finalize__(self, method=\"reindex\")\n\u001b[1;32m   4821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4841\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4842\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4843\u001b[0;31m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4844\u001b[0m             )\n\u001b[1;32m   4845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4887\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4888\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4889\u001b[0;31m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4890\u001b[0m             )\n\u001b[1;32m   4891\u001b[0m             \u001b[0;31m# If we've made a copy once, no need to make another one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_validate_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3783\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3785\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3787\u001b[0m     def reindex(\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "Final_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c249aec-6643-443a-aaad-d3d7f1966e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
